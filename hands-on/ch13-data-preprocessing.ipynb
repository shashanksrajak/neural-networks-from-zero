{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashanksrajak/neural-networks-from-zero/blob/main/hands-on/ch13-data-preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364400d9",
      "metadata": {
        "id": "364400d9"
      },
      "source": [
        "# Ch 13 : Loading and Preprocessing Data\n",
        "\n",
        "In this chapter we aim to learn how to load and preprocess data using `tensorflow` and `keras` apis.\n",
        "\n",
        "At the heart of this process, lies `tf.data` api which has lot of features to manage data for training.\n",
        "\n",
        "Tensorflow doc -> https://www.tensorflow.org/guide/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_U2QoqRimS8a"
      },
      "id": "_U2QoqRimS8a",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf.data API"
      ],
      "metadata": {
        "id": "V52LWzVal2jz"
      },
      "id": "V52LWzVal2jz"
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.range(10)\n",
        "X"
      ],
      "metadata": {
        "id": "ecxk-DJLl0nV",
        "outputId": "acdcf8eb-3949-4bec-b441-51c422e06e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ecxk-DJLl0nV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "metadata": {
        "id": "mwW3oAcDmtNh",
        "outputId": "c99b617b-2dd1-479f-d006-0e276af2603d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mwW3oAcDmtNh",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset:\n",
        "  print(item.numpy())"
      ],
      "metadata": {
        "id": "JT7PUO3nnU1o",
        "outputId": "426dc746-a01b-4f0f-be83-6a75d1848cb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JT7PUO3nnU1o",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: `tf.data` is like a streaming API, we can iterate over the dataset, but we can not index or slice it."
      ],
      "metadata": {
        "id": "cjbIBItEnvfK"
      },
      "id": "cjbIBItEnvfK"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "md3i8xp2nngN",
        "outputId": "3faab8ba-6cc6-49d5-e4ca-7a499708e97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "id": "md3i8xp2nngN",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'_TensorSliceDataset' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-2411785438.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: '_TensorSliceDataset' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chaining Transformations\n",
        "\n",
        "the `dataset` methods do not change the datasets, they create new ones so its better to keep storing them in some variable to use them further."
      ],
      "metadata": {
        "id": "a6tZAeDoo079"
      },
      "id": "a6tZAeDoo079"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.repeat(3).batch(7)\n",
        "\n",
        "for item in dataset:\n",
        "  print(item) # now it will print a batch of 7 instead of just one tensor"
      ],
      "metadata": {
        "id": "uvSXxiGHn257",
        "outputId": "b44eac10-4f25-402d-cef7-e4250ab34d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uvSXxiGHn257",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda x : x*2)\n",
        "\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "aD2rIRv6pbsM",
        "outputId": "3585a6b8-ee16-4a58-9a5a-a240795ee977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aD2rIRv6pbsM",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we only want few items out of all the items, we can use `take(x)`"
      ],
      "metadata": {
        "id": "K4YNv24Gqo_i"
      },
      "id": "K4YNv24Gqo_i"
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset.take(2):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "uIBin53mp_z4",
        "outputId": "3f61c5e8-628d-4c33-f45d-609dd9beb4c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uIBin53mp_z4",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffling the data"
      ],
      "metadata": {
        "id": "rbdZ4MYLq6Rq"
      },
      "id": "rbdZ4MYLq6Rq"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(2)\n",
        "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n",
        "\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "nixDL6HeqgKz",
        "outputId": "6087653a-8981-4184-80e4-89b5307ba1cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nixDL6HeqgKz",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QD5NvZrh2iv6"
      },
      "id": "QD5NvZrh2iv6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}